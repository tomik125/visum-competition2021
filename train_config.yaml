experiment_name: null # null: use current timestamp as experiment name ; str to specify a desired experiment name
seed: 42

DATA:
  product_imgs_dir: /home/master/dataset/train/product_images
  df_products_fn: processed_data/{}/df_products.csv  # {} - placeholder for the split set, i.e. train, valid, or test
  df_outfits_fn: processed_data/{}/df_outfits.csv  # {} - placeholder for the split set, i.e. train, valid, or test
  cache_dir: processed_data/
  imgs_ext: .jpg
  batch_size: 128
  num_workers: 4
  max_prods_per_outfit: 14
  val_split: 0.2
  num_train_outfits: null # null: use whole training dataset; number greater than 0 to truncate the training dataset
  num_valid_outfits:  null # null: use whole validation dataset; number greater than 0 to truncate the validation dataset

INPUT_MODALITY: multimodal  # image or text or multimodal

TOKENIZER:
  run: False
  model: distilbert-base-uncased
  max_length: 100

TEXT_ENCODER:
  model_name: distilbert-base-uncased
  embedding_size: 768
  pretrained: True
  finetune: False
  finetune_start_block: 5  # there are 0-5 blocks
  l2_norm: True
  projection_size: 1024
  dropout: 0.1

IMAGE_ENCODER:
  model_name: resnet50
  embedding_size: 2048
  img_size: 224
  pretrained: True
  finetune: False
  finetune_start_block: 7  # there are 0-8 blocks
  l2_norm: True
  projection_size: 1024
  dropout: 0.1

MULTIMODAL_ENCODER:
  embedding_size: 1024
  l2_norm: True
  dropout: 0.1

TRAINER:
  n_epochs: 30
  log_interval: 50
  save_dir: results/
  resume_path: null  # null: start training from the beginning; str (model_checkpoint_path) for resume training
  max_iter_per_epoch: 8 #00

LOSS:
  margin: 1.0

OPTIMIZER:
  lr: 0.001
  weight_decay: 0.0001

TRANSFORMS:
  crop: 224
  scale:
    - 0.8
    - 1.0
  mean:
    - 0.485
    - 0.456
    - 0.406
  std:
    - 0.229
    - 0.224
    - 0.225
